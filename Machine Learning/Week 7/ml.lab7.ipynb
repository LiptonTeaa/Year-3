{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 7: Regularisation models: Ridge, Lasso, Elastic net, and early stopping. Linear models for classificaton: Logistic regression, and Softmax regression \n",
    "\n",
    "The purpose of this lab work is to illustrate the regularisation of linear regression models such as Ridge regression, Lasso regression, and Elastic net, for preventing overfitting. In addition the early stopping regularisation is illustrated for iterative models such as Stochastic gradient descent (SGD).  Moreover, the purpose of the lab is also to see how linear models such as Logistic regression and Softmax regression work for binary classification and multiclass classification, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks \n",
    "1. Study and run (cell by cell) the code below which illustrates regularisation for regression linear models, that prevents overfitting. Study also the code that illustrates linear classification models such as Logistic and Softmax regressions.\n",
    "\n",
    "2. In the Lab 3 we build several regression models predicting the median house price. You are required to build new models on the same dataset based on Ridge, Lasso and Elastic net by trying 2 values for each hyperparameter of the algorithm, and compare the RMSE performance you get on the test set. \n",
    "\n",
    "3. Similar to (2) above, but tune your models in a CV (cross validation). Use grids for  hyperparameters. \n",
    "\n",
    "4. For the Lasso model obtained in (3), see which features it selects as important (see discussion on feature selection in the lecture). \n",
    "\n",
    "5.  Tackle the exercises provided in the slides of Lecture 6 (or finish at home when you revise your lecture and recomended chapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed, as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "m = 20\n",
    "X = 3 * np.random.rand(m, 1)\n",
    "y = 1 + 0.5 * X + np.random.randn(m, 1) / 1.5\n",
    "X_new = np.linspace(0, 3, 100).reshape(100, 1)\n",
    "#print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.55071465]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularisation hyperparameter for Ridge is as seen in the lecture:\n",
    "# alpha - the strength of regularisation.\n",
    "# Here solver=\"cholesky\" chooses the one of the possible methods to compute the model,\n",
    "# which is based on a closed-form solution (mathematical formula) based on the so called Cholesky method.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\n",
    "ridge_reg.fit(X, y)\n",
    "ridge_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.38390205])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In additon to the closed-form solution illustrated above, Ridge can also be computed \n",
    "# iteratively with gradient descent, using an L2 penalty (see penalty=\"l2\") as discussed in lecture. \n",
    "# Here we illustrate it using Stochastic gradient descent (SGD).\n",
    "# Notice the regularisation hyperparameter alpha. \n",
    "# Due to the random nature of the algorithm (selection of instances to \n",
    "# calculate the gradients and update the coefficients\n",
    "# is done randomly, as seen in lecture), random_state controls the random generator used in the\n",
    "# selection of these instances.\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(penalty=\"l2\", alpha=1, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53788174])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularisation hyperparameter for Lasso is as seen in the lecture:\n",
    "# alpha - the strength of regularisation.\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X, y)\n",
    "lasso_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26167212])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the coefficient(s) of the Lasso model: \n",
    "\n",
    "lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note on using Lasso for feature selection: \n",
    "# For complex datasets with many features, you can check which\n",
    "# features have a coefficient equal to 0 in the Lasso model. Those features are\n",
    "# not considered important by the model and so not used since they have a 0 coefficient. \n",
    "# The features with non- zero coefficients can be seen as the features selected by the Lasso model.\n",
    "# Hence Lasso algo is not only used for building a model, but can be used for feature selection too.\n",
    "# For a dataset which is very large and has many features, or for which you suspect it may have some \n",
    "# unuseful features, to prevent a large amount of computation, \n",
    "# you can do a feature selection with Lasso (which is cheap to compute), \n",
    "# and then use another algo to build a more powerful (possibly more computationally expensive) \n",
    "# model on the selected features to reach better predictions. \n",
    "# Indeed, this method may eliminate unuseful features, and may make the\n",
    "# computation amount more feasable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45526648])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso can also be computed iteratively with Stochastic gradient descent algo\n",
    "# as seen for Ridge above. In this case we use L1 penalty \n",
    "# as discussed in lecture (see penalty=\"l1\" in the command). \n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(penalty=\"l1\", alpha=0.1, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.54333232])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularisation hyperparameters for Elastic net are as seen in the lecture:\n",
    "# alpha - the strength of regularisation, and l1_ratio (r in the slides)\n",
    "# which controls the mixture of Lasso (L1 regularisation) and Ridge (L2 regularisation) \n",
    "# as part of Elastic net. \n",
    "# l1_ratio=0.5 means we have 50% of Lasso and remaining 50% of Ridge. \n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(X, y)\n",
    "elastic_net.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45913103])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elastic net can also be computed iteratively with Stochastic gradient descent\n",
    "# as seen for Ridge and Lasso above. In this case we use both L1 and L2 penalties \n",
    "# as discussed in lecture, which is set by  the parameter penalty=\"elasticnet\" in the command below. \n",
    "# In additon we specify the strengh of rgularisation alpha=0.1, and \n",
    "# the l1_ratio=0.5 (hyperparametr r in the lecture slides)\n",
    "# that controls the mixture of Lasso and Ridge as explained in the lecture.\n",
    "# l1_ratio=0.5 means we have 50% of Lasso and remaining 50% of Ridge. \n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(penalty=\"elasticnet\", alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35926086])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As seen in lecture, early stopping is another (simple and useful) regularisation method, \n",
    "# constraining the number of iterations an algo does, to prevent overfitting. \n",
    "# In the example below, the iterative updating of the model's coefficients \n",
    "# stops when the error starts to increase on the validation set as discussed in the lecture, \n",
    "# or in other words, it stops to decrease.\n",
    "# Here, early stopping is used for this Lasso model implemented with Stochastic gradient descent,\n",
    "# and the validation set is 30% of the dataset (see validation_fraction=0.3).\n",
    "# Training will stop (early) when the loss (error) doesn't improve for a number of steps\n",
    "# given by n_iter_no_change=5. \n",
    "# That is, if (loss > best_loss - tol) for 5 consecutive epochs, there is no significant \n",
    "# improvement (decrease) of the loss by at least a tolerance level tol=1e-3, and training stops. \n",
    "# Such details on algo parameters can be consulted online as sklearn has an excellent \n",
    "# documentation: google sklean and the name of algo (here SDGRegressor)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(penalty=\"l1\", alpha=0.1, \n",
    "                       max_iter=1000, early_stopping=True, validation_fraction=0.3, \n",
    "                       n_iter_no_change=5, tol=1e-3, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure logistic_function_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how the sigmoid function (or logistic function) looks like.\n",
    "# This function is used in Logistic Regression for classification to compute the \n",
    "# probability of a class.\n",
    "# (The function is used also in neural nets - studied in next labs)\n",
    "\n",
    "t = np.linspace(-10, 10, 100)\n",
    "sig = 1 / (1 + np.exp(-t))\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot([-10, 10], [0, 0], \"k-\")\n",
    "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
    "plt.plot([-10, 10], [1, 1], \"k:\")\n",
    "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
    "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend(loc=\"upper left\", fontsize=20)\n",
    "plt.axis([-10, 10, -0.1, 1.1])\n",
    "save_fig(\"logistic_function_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'target',\n",
       " 'frame',\n",
       " 'target_names',\n",
       " 'DESCR',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'data_module']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we use the iris dataset, available in sklearn library, to illustrate the simple Logistic regression for 2 classes, \n",
    "# and Softmax regression for multiple classes\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature values\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# a full description of the data\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\.conda\\envs\\DM\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# We prepare data to learn a simple logistic regression model predicting the plant based on 1 feature only: petal width \n",
    "# and it is a binary classification: class 1 (Iris virginica) and class 0 (not Iris Virginica)\n",
    "\n",
    "X = iris[\"data\"][:, 3:]  # petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.int)  # 1 if Iris virginica, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficint=  [[4.3330846]] , intercept=  [-7.1947083]\n"
     ]
    }
   ],
   "source": [
    "# Let's see the coefficient w1 of the feature petal width, and the intercept w0 in the logistic model\n",
    "# You can access these as atributes of the model: coef_ and intercept_ \n",
    "# See these in the details of LogisticRegression class in the sklearn documentation \n",
    "# (as usual, just google \"LogisticRegression sklearn\")\n",
    "\n",
    "print('coefficint= ', log_reg.coef_, ', intercept= ', log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the probability computed by the logistic model for class Iris virginica is $\\sigma(t) = \\frac{1}{1 + e^{-t}}$ where $t=4.3330846 * x_1 -7.1947083$ and $x_1$ is the petal width feature.\n",
    "The probability for the class Not Iris virginica is the complement with respect to 100% of the above probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Probability')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the probability curves for Iris virginica (green) and not Iris virginica (blue) based on 1 feature: petal width\n",
    "# We see from this chart that the probability of virginica increases with the petal width\n",
    "\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris virginica\")\n",
    "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probability\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66066066])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decison boudary as the point where both classes in this binalry classification are equally probable \n",
    "# When Petal width is about 1.66, both classes have probability 0.5, that's a decision boundary\n",
    "\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember this model is for binary classification: class 1 (Iris virginica) and class 0 (not Iris Virginica)\n",
    "# Now we predict class for plants with Petal with 1.7 and 1.5\n",
    "# We see the 1st is predicted as class 1 (Iris virginica) and the 2nd as class 0 (not Iris Virginica)\n",
    "\n",
    "log_reg.predict([[1.7], [1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression: used with multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Prepare data to make predictions based on 2 features petal length, petal width, \n",
    "# and all the 3 classes in the dataset\n",
    "\n",
    "print(iris.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, multi_class='multinomial', random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The hyperparameter controlling the regularization strength of a sklearn LogisticRegression model is not alpha \n",
    "# (as in other linear models), but its inverse: C. The higher the value of C, the less the model is regularised.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n",
    "softmax_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the class of a plant with petal lenth 5 and petal width 2\n",
    "# we can see the predicted class is 2 (virginica)\n",
    "\n",
    "softmax_reg.predict([[5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.38014896e-07, 5.74929995e-02, 9.42506362e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the probabilities of the 3 classes for this plant\n",
    "# We see they add up to 100%, and that the largest probability about 94% is for the the 3rd class - virginica\n",
    "\n",
    "softmax_reg.predict_proba([[5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
